import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

# Chargement du dataset
df = pd.read_csv("../CSV/Encoded/OneHot/poker_encoded_onehot(10000).csv", header=None)  # Pas de header si pas prÃ©cisÃ© dans le fichier

# SÃ©paration correcte
X_preflop = df.iloc[:, :34]     # Main seulement
X_fullboard = df.iloc[:, :119]   # Main + board

y_preflop = df.iloc[:, 119]      # preflop_win_rate
y_fullboard = df.iloc[:, 120]    # fullboard_win_rate

# ModÃ¨le pour preflop
print("ğŸ¯ Preflop Win Rate")
mse_list_p = []
r2_list_p = []
mae_list_p = []
explained_variance_p = []
for i in range(10):
    # SÃ©paration du dataset : 60% pour entraÃ®nement, 40% pour test et validation
    X_train_p, X_temp_p, y_train_p, y_temp_p = train_test_split(X_preflop, y_preflop, test_size=0.4)

    # SÃ©paration des 40% restants : 50% pour validation, 50% pour test (soit 20% du dataset total)
    X_val_p, X_test_p, y_val_p, y_test_p = train_test_split(X_temp_p, y_temp_p, test_size=0.5)

    # EntraÃ®nement du modÃ¨le
    model_p = RandomForestRegressor()
    model_p.fit(X_train_p, y_train_p)

    # PrÃ©dictions sur le set de test
    y_pred_p = model_p.predict(X_test_p)

    # Calcul des mÃ©triques
    mse_list_p.append(mean_squared_error(y_test_p, y_pred_p))
    r2_list_p.append(r2_score(y_test_p, y_pred_p))
    mae_list_p.append(mean_absolute_error(y_test_p, y_pred_p))
    explained_variance_p.append(model_p.score(X_test_p, y_test_p))  # RÂ² sur les donnÃ©es de test

print("MSE moyen :", np.mean(mse_list_p))
print("RÂ² moyen  :", np.mean(r2_list_p))
print("MAE moyen :", np.mean(mae_list_p))
print("Variance expliquÃ©e moyenne :", np.mean(explained_variance_p))

# ModÃ¨le pour fullboard
print("\nğŸƒ Fullboard Win Rate")
mse_list_f = []
r2_list_f = []
mae_list_f = []
explained_variance_f = []

for i in range(10):
    # SÃ©paration du dataset : 60% pour entraÃ®nement, 40% pour test et validation
    X_train_f, X_temp_f, y_train_f, y_temp_f = train_test_split(X_fullboard, y_fullboard, test_size=0.4)

    # SÃ©paration des 40% restants : 50% pour validation, 50% pour test (soit 20% du dataset total)
    X_val_f, X_test_f, y_val_f, y_test_f = train_test_split(X_temp_f, y_temp_f, test_size=0.5)

    # EntraÃ®nement du modÃ¨le
    model_f = RandomForestRegressor()
    model_f.fit(X_train_f, y_train_f)

    # PrÃ©dictions sur le set de test
    y_pred_f = model_f.predict(X_test_f)

    # Calcul des mÃ©triques
    mse_list_f.append(mean_squared_error(y_test_f, y_pred_f))
    r2_list_f.append(r2_score(y_test_f, y_pred_f))
    mae_list_f.append(mean_absolute_error(y_test_f, y_pred_f))
    explained_variance_f.append(model_f.score(X_test_f, y_test_f))  # RÂ² sur les donnÃ©es de test

print("MSE moyen :", np.mean(mse_list_f))
print("RÂ² moyen  :", np.mean(r2_list_f))
print("MAE moyen :", np.mean(mae_list_f))
print("Variance expliquÃ©e moyenne :", np.mean(explained_variance_f))